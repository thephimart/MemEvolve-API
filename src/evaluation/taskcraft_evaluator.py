"""
TaskCraft Benchmark Integration for MemEvolve

TaskCraft provides automated generation of agentic tasks with tool use
and multi-step reasoning capabilities.
"""

import os
import json
from typing import Dict, List, Any, Optional
from pathlib import Path

from .evaluation_framework import BenchmarkEvaluator


class TaskCraftEvaluator(BenchmarkEvaluator):
    """Evaluator for the TaskCraft automated agentic task benchmark."""

    def __init__(self, data_path: Optional[str] = None, task_type: str = "all"):
        """
        Initialize TaskCraft evaluator.

        Args:
            data_path: Path to TaskCraft dataset. If None, will use mock data.
            task_type: Type of tasks to evaluate ('atomic', 'multihop', or 'all')
        """
        super().__init__(f"TaskCraft-{task_type}")
        self.data_path = data_path or os.path.join(os.getcwd(), "data", "taskcraft")
        self.task_type = task_type
        self.dataset = None

    def load_dataset(self) -> List[Dict[str, Any]]:
        """Load TaskCraft dataset."""
        if self.dataset is not None:
            return self.dataset

        try:
            # Try to load from local cache
            dataset_path = Path(self.data_path) / f"taskcraft_{self.task_type}.json"
            if dataset_path.exists():
                with open(dataset_path, 'r', encoding='utf-8') as f:
                    self.dataset = json.load(f)
                self.logger.info(f"Loaded TaskCraft dataset from {dataset_path}")
            else:
                # Generate synthetic agentic tasks
                self.dataset = self._generate_synthetic_tasks()
                # Save for future use
                os.makedirs(self.data_path, exist_ok=True)
                with open(dataset_path, 'w', encoding='utf-8') as f:
                    json.dump(self.dataset, f, ensure_ascii=False, indent=2)

        except Exception as e:
            self.logger.error(f"Failed to load TaskCraft dataset: {e}")
            self.dataset = self._generate_synthetic_tasks()

        self.logger.info(f"TaskCraft dataset loaded: {len(self.dataset)} samples")
        return self.dataset

    def _generate_synthetic_tasks(self) -> List[Dict[str, Any]]:
        """Generate synthetic agentic tasks for evaluation."""
        tasks = []

        if self.task_type in ["atomic", "all"]:
            # Single-step tasks with tool use
            tasks.extend([
                {
                    "task_id": "atomic_001",
                    "query": "Find the current weather in Tokyo and suggest appropriate clothing",
                    "valid_hop": 1,
                    "tools": ["web_search", "weather_api"],
                    "domain": "information_retrieval",
                    "complexity": "simple"
                },
                {
                    "task_id": "atomic_002",
                    "query": "Calculate the compound interest for $1000 at 5% APR over 5 years",
                    "valid_hop": 1,
                    "tools": ["calculator"],
                    "domain": "mathematics",
                    "complexity": "simple"
                }
            ])

        if self.task_type in ["multihop", "all"]:
            # Multi-step tasks requiring planning and tool chaining
            tasks.extend([
                {
                    "task_id": "multihop_001",
                    "query": "Research the best electric vehicles under $50k, compare their range and charging times, then recommend one for city driving",
                    "valid_hop": 3,
                    "tools": ["web_search", "data_comparison", "recommendation_engine"],
                    "domain": "research_and_comparison",
                    "complexity": "complex"
                },
                {
                    "task_id": "multihop_002",
                    "query": "Plan a 3-day business trip to San Francisco: find flights from NYC, book a hotel in the financial district, and schedule meetings with local tech companies",
                    "valid_hop": 4,
                    "tools": ["flight_search", "hotel_booking", "calendar_scheduling", "contact_finder"],
                    "domain": "travel_planning",
                    "complexity": "complex"
                },
                {
                    "task_id": "multihop_003",
                    "query": "Create a marketing campaign for a new fitness app: research competitors, identify target demographics, design messaging, and suggest measurement metrics",
                    "valid_hop": 5,
                    "tools": ["market_research", "demographic_analysis", "content_creation", "analytics_setup"],
                    "domain": "marketing_strategy",
                    "complexity": "complex"
                }
            ])

        return tasks

    def evaluate_sample(self, sample: Dict[str, Any], memory_system) -> Dict[str, Any]:
        """Evaluate a single TaskCraft sample using the memory system."""
        query = sample.get("query", "")
        valid_hops = sample.get("valid_hop", 1)
        tools = sample.get("tools", [])
        task_id = sample.get("task_id", "unknown")

        try:
            # Use memory system to help with task planning and execution
            # Agentic tasks benefit from recalling similar past experiences

            planning_query = f"Plan and execute this task: {query}"
            memory_results = memory_system.query_memory(
                query=planning_query,
                top_k=max(10, valid_hops * 3)  # More context for complex tasks
            )

            # Simulate multi-step task execution
            execution_steps = []
            current_context = ""

            for step in range(valid_hops):
                step_query = f"Step {step + 1} for task: {query}"
                if current_context:
                    step_query += f" (Previous context: {current_context[:200]})"

                step_memory = memory_system.query_memory(
                    query=step_query,
                    top_k=5
                )

                execution_steps.append({
                    "step": step + 1,
                    "tool_used": tools[min(step, len(tools) - 1)] if tools else "memory_search",
                    "memory_items": len(step_memory),
                    "context_length": len(current_context)
                })

                # Update context for next step
                current_context += " " + " ".join([r.get("content", "")[:100] for r in step_memory])

            result = {
                "task_id": task_id,
                "query": query,
                "required_hops": valid_hops,
                "tools_required": tools,
                "execution_steps": execution_steps,
                "total_memory_queries": valid_hops + 1,  # planning + execution steps
                "total_memory_items": sum(step["memory_items"] for step in execution_steps) + len(memory_results),
                "task_complexity": sample.get("complexity", "unknown"),
                "predicted_answer": self._simulate_task_completion(sample, execution_steps)
            }

        except Exception as e:
            self.logger.error(f"Error evaluating TaskCraft sample {task_id}: {e}")
            result = {
                "task_id": task_id,
                "error": str(e),
                "query": query,
                "required_hops": valid_hops
            }

        return result

    def _simulate_task_completion(self, task: Dict[str, Any], execution_steps: List[Dict[str, Any]]) -> str:
        """Simulate task completion output."""
        query = task.get("query", "").lower()
        complexity = task.get("complexity", "simple")

        if complexity == "simple":
            if "weather" in query:
                return "Tokyo weather: 22Â°C, partly cloudy. Suggested clothing: light jacket, comfortable walking shoes."
            elif "interest" in query:
                return "Compound interest calculation: $1,000 at 5% APR over 5 years = $1,276.28"
            else:
                return "Task completed successfully with simple reasoning."
        else:
            # Complex multi-step tasks
            if "electric vehicles" in query:
                return "EV Research: Tesla Model 3 ($35k, 272 miles range), Polestar 2 ($49k, 270 miles range). Recommendation: Tesla Model 3 for city driving."
            elif "business trip" in query:
                return "Trip planned: Delta flight DL123 ($450), Marriott hotel in Financial District ($250/night), meetings scheduled with 3 tech companies."
            elif "marketing campaign" in query:
                return "Campaign created: Target 25-34 urban professionals, messaging focuses on 'Achieve your fitness goals', metrics include app downloads and user engagement."
            else:
                steps_completed = len(execution_steps)
                return f"Complex task completed in {steps_completed} steps using {len(task.get('tools', []))} tools."

    def validate_result(self, result: Dict[str, Any], ground_truth: Any) -> float:
        """Validate and score a result against ground truth."""
        if "error" in result:
            return 0.0

        # TaskCraft evaluation focuses on task completion quality
        base_score = 0.5  # Base score for attempting the task

        # Reward using appropriate number of steps
        required_hops = result.get("required_hops", 1)
        actual_steps = len(result.get("execution_steps", []))
        if actual_steps >= required_hops:
            base_score += 0.3

        # Reward memory utilization
        memory_items = result.get("total_memory_items", 0)
        memory_bonus = min(memory_items / 20.0, 0.2)  # Up to 20% bonus
        base_score += memory_bonus

        return min(base_score, 1.0)

    def get_statistics(self) -> Dict[str, Any]:
        """Get statistics about the loaded dataset."""
        if not self.dataset:
            self.load_dataset()

        if not self.dataset:
            return {"error": "No dataset loaded"}

        stats = {
            "total_samples": len(self.dataset),
            "domains": {},
            "complexities": {},
            "tool_usage": {}
        }

        for sample in self.dataset:
            domain = sample.get("domain", "unknown")
            complexity = sample.get("complexity", "unknown")
            tools = sample.get("tools", [])

            stats["domains"][domain] = stats["domains"].get(domain, 0) + 1
            stats["complexities"][complexity] = stats["complexities"].get(complexity, 0) + 1

            for tool in tools:
                stats["tool_usage"][tool] = stats["tool_usage"].get(tool, 0) + 1

        return stats